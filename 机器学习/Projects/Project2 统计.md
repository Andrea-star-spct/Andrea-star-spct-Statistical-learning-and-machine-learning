**华东师范大学数据科学与工程学院实验报告** 

| **课程名称**：统计学习与机器方法                  | **年级**：2019     | **实践成绩**：        |
| ------------------------------------------------- | ------------------ | --------------------- |
| **指导教师**：董启文                              | **姓名**：周辛娜   | **学号**：10195501442 |
| **上机实践**： Project2三种分布贝叶斯解决文本分类 | **上机实践时间**： | 2021.12.20            |



## 任务：

1000个文档分成20类，五重交叉验证结果。



## 实验数据集：

从(https://www.cs.cmu.edu/afs/cs.cmu.edu/project/theo-11/www/naive-bayes.html)下载数据集，数据集包含来自 20 个新闻组中每个组的 1000 个文档。由于下载下来是文本的形式，并不是现成的.csv的格式，需要进行整理。



## 一、探索文本数据

#### 经过整理后的数据全貌：

<img src="C:\Users\asus\AppData\Roaming\Typora\typora-user-images\image-20211222111726764.png" alt="image-20211222111726764" style="zoom: 67%;" />

数据集有2000行，3列，每行表示一个新闻，第一列不需要，第二列是data，对应的新闻的文本内容，第三列是新闻所属的类别。

查看第一条新闻的内容：

![image-20211222111851707](C:\Users\asus\AppData\Roaming\Typora\typora-user-images\image-20211222111851707.png)

查看一共20个类别：

<img src="C:\Users\asus\AppData\Roaming\Typora\typora-user-images\image-20211222111931405.png" alt="image-20211222111931405" style="zoom: 67%;" />

#### 接下来看样本均不均衡，这是要代入朴素贝叶斯模型之前需要关注的：

<img src="C:\Users\asus\AppData\Roaming\Typora\typora-user-images\image-20211222112059957.png" alt="image-20211222112059957" style="zoom: 67%;" />

可以看到总体是比较均衡



## 二、文本特征提取

### 使用TF-IDF向量计数

在开始分类之前，必须先将文本编码成数字，一般常用的方法是单词计数向量计数和TF-IDF向量计数方法。

1. 单词计数向量，在这种技术中，一个样本可以包含一段话或者一篇文章，这个样本如果出现了10个单词，就会有10个特征，每个特征代表一个单词，特征的取值代表这个单词在这个样本中总共出现了几次，是一个离散的，代表次数的整数。
   在sklearn中，单词计数向量计数可以通过feature_extraction.text模块中的CountVectorizer类实现.

2. 可以预见，如果使用单词计数向量，可能会导致一部分常用词频繁出现在矩阵中并且占有很高的权重，对分类来说，这明显是对算法的一种误导。为了解决这个问题，比起使用次数，使用单词在句子中所占的比例来编码单词，这就是TF-IDF方法，词频逆文档频率，是通过单词在文档中出现的频率来衡量其权重，IDF的大小与一个词的常见程度成反比，这个词越常见，编码后为它设置的权重就会倾向于越小，从而来压制频繁出现的一些无意义的词。
   在sklearn中，使用feature_extraction.text中类TfidVectorizer来执行这种编码

在实验初期，两种方法都用了，但是TF-IDF向量计数效果要好一些，所以就使用TF-IDF向量计数进行文本特征提取。



## 三、划分训练集测试集

<img src="C:\Users\asus\AppData\Roaming\Typora\typora-user-images\image-20211221211958215.png" alt="image-20211221211958215" style="zoom:80%;" />



## 四、归一化

在本实验集上，归一化并没有什么实质的效果。



## 五、构建模型：

### 1. 先使用三种不同分布的朴素贝叶斯模型先进行预测，分别是Multinomial，Complement，Bernuolli

#### 模型介绍：

朴素贝叶斯有各种各样的假设，除了“朴素”的假设即假设变量之间相互独立的假设，还有对于概率分布的假设，包括多项式朴素贝叶斯multinomialNB、伯努利朴素贝叶斯BernuolliNB（二项分布，数据集中存在多个特征，但每个特征都是二分类的，可以用布尔变量表示，由于本数据集中有20个类，那么可以使用类中专门用来二值化的参数binarize来改变数据）、高斯朴素贝叶斯和补集朴素贝叶斯。

1. 多项式朴素贝叶斯适用于二项分布、多项分布，擅长分类型变量，多项式朴素贝叶斯的特征矩阵经常是稀疏矩阵，所以经常被用于文本分类。

2. 伯努利朴素贝叶斯和多项式朴素贝叶斯非常相似，常用于处理文本分类数据，但由于伯努利朴素贝叶斯处理二项分布，所以更在意存在与否，而不是出现多少次，这是两者的根本不同。在文本分类的情况下，伯努利朴素贝叶斯可以使用单词出现向量而不是单词计数向量来训练分类器，在文档较短的数据集上，伯努利朴素贝叶斯效果更好。它适用于二项分布，数据集中存在多个特征，但每个特征都是二分类的，可以用布尔变量表示，由于本数据集中有20个类，那么可以使用类中专门用来二值化的参数binarize来改变数据，在本实验中也试着采用binarize，但效果反而更差，所以就不进行该项操作了。

3. 高斯朴素贝叶斯是不接受稀疏矩阵的，而这里恰恰就是稀疏矩阵，所以在本次实验中就无法使用高斯朴素贝叶斯。

4. 补集朴素贝叶斯是多项式朴素贝叶斯的改进，它能够解决样本不平衡的问题，并且能够一定程度上忽略朴素假设。


超参数：平滑系数 alpha，是为了防止训练数据中出现过的一些词汇没有出现在测试集中导致0概率，之后会采用五折交叉验证得到这三种模型当超参数取哪个值的时候表现最优。

#### 当平滑系数 alpha默认为1时的实验结果：

<img src="C:\Users\asus\Desktop\11.png" style="zoom: 67%;" />





为了对比更加清晰，用表格显示上面的结果：

| 模型        | 用时 | accuracy |
| ----------- | ---- | -------- |
| Multinomial | 7ms  | 0.692    |
| Complement  | 4ms  | 0.808    |
| Bernuolli   | 10ms | 0.476    |

在平滑系数 alpha默认为1时，Complement不仅Accuracy最高而且用时最短，表现最好



### 2. 分别在这三种模型下通过交叉验证，选择最优超参数

#### 交叉验证介绍：

本次实验采用五折交叉验证，5-fold cross validation，将数据集分为3部分，training set、validation set和test set，一般划分的比例是3:1:1，三者之间没有交集。



超参数alpha的取值范围：0.00001，0.0001，0.0005，0.001，0.005，0.01，0.05，0.1，0.2，0.5，0.7，0.9，1。由于有三个模型，所以先要画出随着alpha的变化，三种不同模型的平均accuracy的变化，进而选择较优的模型，然后针对该模型，画出对应的随着alpha变化，对应的交叉验证图，选择平均准确率最高且方差较小的alpha。也就是不断增大alpha，对于每一个alpha，计算验证集上的平均accuracy和standard deviation，选取accuracy较大且表现稳定的alpha。



由于参数的搜索空间比较大，而且又是五折交叉验证，比较耗时，对于更大型的数据集合深度学习来说，较少使用，本实验的数据集并不大，所以耗时还能接受。



#### 交叉验证过程：

以下为交叉验证的过程。

<img src="C:\Users\asus\Desktop\QQ截图20211222165938.png" style="zoom: 50%;" />

#### 结果：

<img src="C:\Users\asus\AppData\Roaming\Typora\typora-user-images\image-20211228163255155.png" alt="image-20211228163255155" style="zoom:80%;" />

由此可以看到，Multinomial和Bernuolli的classification accuracy均是先升高再下降，但是这两种方法的最大值要小于complement的最大值，complement的classification accuracy是明显要高于Multinomial和Bernuolli，所以接下来用complement最好的模型参数来看看最后的结果



#### 选取平均准确率最高且方差较小的alpha作为最后模型的参数：

<img src="C:\Users\asus\AppData\Roaming\Typora\typora-user-images\image-20211228163314807.png" alt="image-20211228163314807" style="zoom: 80%;" />



## 六、最后达到的效果

<img src="C:\Users\asus\AppData\Roaming\Typora\typora-user-images\image-20211228165600044.png" alt="image-20211228165600044" style="zoom: 67%;" />



最后达到83%的准确率，效果还不错。



## 七、总结

​	本次实验采用用三种不同分布朴素贝叶斯解决文本分类，通过整理数据、探索文本数据、文本特征提取、划分训练集测试集、归一化、构建模型、先使用三种不同分布的朴素贝叶斯模型先进行预测，分别是Multinomial，Complement，Bernuolli，分别在这三种模型下通过交叉验证，选择最优超参数，最后用complement最好的模型参数来看最后的结果。最终达到了83%的准确率。

​	对于本次实验的数据集来说，Complement是最适合的贝叶斯模型，不仅运行速度是最快的而且准确率是最高的，但是对于不同的数据集，可能Bernuolli、Multinomial的表现会更优秀，这个要根据具体情况确定。


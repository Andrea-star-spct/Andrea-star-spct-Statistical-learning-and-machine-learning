heart disease

1. random forest
2. mlp
3. adaboost
4.knn
5. naive bayes
6.nn
8.svm rbf kernal

可以看到mlp,nn

分类问题 交叉熵损失函数

K-NN
kNN算法的核心思想是如果一个样本在特征空间中的k个最相邻的样本中的大多数属于某一个类别，则该样本也属于这个类别，并具有这个类别上样本的特性。该方法在确定分类决策上只依据最邻近的一个或者几个样本的类别来决定待分样本所属的类别。 kNN方法在类别决策时，只与极少量的相邻样本有关。由于kNN方法主要靠周围有限的邻近的样本，而不是靠判别类域的方法来确定所属类别的，因此对于类域的交叉或重叠较多的待分样本集来说，kNN方法较其他方法更为适合。

一般来说代入模型都要使用one-hot编码，如果不实用one-hot编码，可以看到在本次实验的数据集上的影响是不大的

模型分类效果不好的原因

1.超参数设置不合理
2.样本数据的特征工程没有做好
3.模型没有选对，模型不适合这个分类

k的取值问题：学习曲线&交叉验证选取K值
K值较小，则模型复杂度较高，容易发生过拟合，学习的估计误差会增大，预测结果对近邻的实例点非常敏感。
K值较大可以减少学习的估计误差，但是学习的近似误差会增大，与输入实例较远的训练实例也会对预测起作用，使预测发生错误，k值增大模型的复杂度会下降。在应用中，k值一般取一个比较小的值，通常采用交叉验证法来来选取最优的K值。
适用场景
小数据场景，样本为几千，几万的
K折交叉验证
目的：
选出最为适合的模型超参数的取值，然后将超参数的值作用到模型的创建中。
思想：
将样本的训练数据交叉的拆分出不同的训练集和验证集，使用交叉拆分出不同的训练集和验证集测分别试模型的精准度，然就求出的精准度的均值就是此次交叉验证的结果。将交叉验证作用到不同的超参数中，选取出精准度最高的超参数作为模型创建的超参数即可！
实现思路：
将数据集平均分割成K个等份
使用1份数据作为测试数据，其余作为训练数据
计算测试准确率
使用不同的测试集，重复2、3步骤
对准确率做平均，作为对未知数据预测准确率的估计


进行特征选择


交叉验证使用的api是
from sklearn.model_selection import cross_val_score
cross_val_score(estimator,X,y,cv):
estimator:模型对象
X,y:训练集数据
cv：折数 

决策树之所以能够运行非常快速是因为sklearn中的分类树在选择特征时有所偷懒，没有计算全部特征的信息熵而是随机选择了一部分特征来进行计算，但是决策树的运算效率随着样本量逐渐增大会越来越慢，但朴素贝叶斯却可以在很少的样本上获得不错的结果，因此可以预料，随着样本量的逐渐增加贝叶斯会逐渐变得比决策树更快，朴素贝叶斯计算速度远远胜过SVM，随机森林这样复杂的模型，逻辑回归的运行受到最大迭代次数的强烈影响和输入数据的影响，逻辑回归一般在线性数据上运行都比较快，在这里应该是受到了稀疏矩阵的影响。
朴素贝叶斯的分类效果其实不如其他分类器，贝叶斯天生学习能力比较弱。
并且随着训练样本量的逐渐增大，其他模型的训练拟合都保持在100%的水平，但贝叶斯的训练准确率却逐渐下降，这证明样本量越大，贝叶斯需要学习的东西越多，对训练集的拟合程度也越来越差，反而比较少量的样本可以让贝叶斯还有较高的训练准确率。

再来看过拟合的问题，首先可以观察到，所有模型在样本量很少的时候都是处于过拟合的状态，即在训练集上表现好，测试集上表现糟糕，但随着样本的逐渐增多，过拟合问题就逐渐消失了，不过每个模型的处理手段不同。比较强大的分类器，如SVM和随机森林、逻辑回归是依靠快速升高模型在测试集上的表现来减轻过拟合问题，相对的，决策树虽然也是通过提高模型在测试集上的表现来减轻过拟合，但随着训练样本的增加，模型在测试集上的表现改善非常缓慢。
朴素贝叶斯不同，是依赖训练集上的准确率下降，测试集上的准确率上升来解决过拟合的问题。

接下来，看看每个算法在测试集上的拟合结果，即泛化误差的大小，随着训练样本数量的上升，所有模型的测试表现都上升了，但贝叶斯和决策树在测试集上的表现远远不如SVM，随机森林和逻辑回归。
SVM在训练数据量增大到1500个样本左右的时候，测试集上的表现已经非常接近100%，而随机森林和逻辑回归的表现也在95%以上，而决策树和朴素贝叶斯还徘徊在85%左右。
但是这两个模型所面临的情况十分不同，决策树虽然测试结果不高，但是依然具有潜力，因为它的过拟合现象非常严重，可以通过剪枝来让决策树的测试结果逼近训练结果。
然而贝叶斯的过拟合现象在训练样本达到1500左右的时候已经几乎不存在了，在训练集上的分数和测试集上的分数非常接近，只有在非常少的时候测试集上的分数才能够比训练集上的结果，所以基本可以判断，85%左右就是贝叶斯在这个数据集上的极限了，可以预测，如果进行调参，那么决策树最后应该可以达到90%左右的预测准确率，但贝叶斯却几乎没有潜力了。
在这个对比之下，可以看出：贝叶斯速度很快，但分类效果一般，并且初次训练之后的结果就很接近算法的极限，几乎没有调参的余地，也就是说，如果追求对概率的预测，并且希望越准确越好，应该先选择逻辑回归。
如果数据很复杂，是稀疏矩阵，那么用贝叶斯也是一个比较好的选择
